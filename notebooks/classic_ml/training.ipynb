{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fab5ae6bd8c4c15",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba972a7119815d97",
   "metadata": {},
   "source": [
    "## Выборочные статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867831ab0d69e2a",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7869e18d86d6317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:56:12.404809Z",
     "start_time": "2025-04-23T19:56:12.390933Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import librosa\n",
    "import json\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "from typing import Any, Sequence\n",
    "from utils import RAW_DATA_PATH, DATA_PATH, CSV_PATH\n",
    "from sklearn.pipeline import Pipeline\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "type FloatArray = NDArray[np.floating[Any]]\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd6a1d839c3a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:13:52.243530Z",
     "start_time": "2025-04-23T19:13:50.768984Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(RAW_DATA_PATH / 'train.feather.lz4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be4b8abd1caf7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:14:05.097928Z",
     "start_time": "2025-04-23T19:14:05.076099Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'Pronunciation'\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b70a4a5431b34067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:25:10.868426Z",
     "start_time": "2025-04-23T19:25:10.856437Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c45e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import baseline_transformer as btf\n",
    "importlib.reload(btf)\n",
    "\n",
    "categorical_features = ['Word ID']\n",
    "numeric_features = X_train.drop(columns=categorical_features).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('btf', btf.BaselineTransformer(), numeric_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c12e4a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc_pr</th>\n",
       "      <td>0.143026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dummy LogisticRegression RandomForest XGBoost CatBoost\n",
       "auc_pr  0.143026                NaN          NaN     NaN      NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(index=['auc_pr'], columns=['Dummy', 'LogisticRegression', 'RandomForest', 'XGBoost', 'CatBoost'])\n",
    "metrics['Dummy'] = (y_train > 0).sum() / len(X_train)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7d6cde29a90af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T19:54:37.297763Z",
     "start_time": "2025-04-23T19:48:16.752009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 16:57:50,204] A new study created in memory with name: no-name-5d15aa5c-9339-45c3-9673-903125eac618\n",
      "[I 2025-04-24 16:58:11,947] Trial 0 finished with value: 0.24268868637021523 and parameters: {'C': 10251.117794754602, 'max_iter': 4805, 'k': 166}. Best is trial 0 with value: 0.24268868637021523.\n",
      "[I 2025-04-24 16:58:31,281] Trial 1 finished with value: 0.23452529207291806 and parameters: {'C': 99132.11476085639, 'max_iter': 4340, 'k': 142}. Best is trial 0 with value: 0.24268868637021523.\n",
      "[I 2025-04-24 17:04:45,209] Trial 2 finished with value: 0.27100842287241084 and parameters: {'C': 13334.648885594384, 'max_iter': 3446, 'k': 263}. Best is trial 2 with value: 0.27100842287241084.\n",
      "[I 2025-04-24 17:05:04,646] Trial 3 finished with value: 0.24639376347679082 and parameters: {'C': 1.4625062091225385, 'max_iter': 4367, 'k': 162}. Best is trial 2 with value: 0.27100842287241084.\n",
      "[I 2025-04-24 17:05:23,797] Trial 4 finished with value: 0.25765637704643485 and parameters: {'C': 2493.053705236766, 'max_iter': 3239, 'k': 187}. Best is trial 2 with value: 0.27100842287241084.\n",
      "[I 2025-04-24 17:05:43,305] Trial 5 finished with value: 0.2508390943624146 and parameters: {'C': 0.0002844352964955451, 'max_iter': 3100, 'k': 119}. Best is trial 2 with value: 0.27100842287241084.\n",
      "[I 2025-04-24 17:06:02,405] Trial 6 finished with value: 0.26991001286277716 and parameters: {'C': 12.490678677040394, 'max_iter': 3090, 'k': 246}. Best is trial 2 with value: 0.27100842287241084.\n",
      "[I 2025-04-24 17:06:20,974] Trial 7 finished with value: 0.2731404967843611 and parameters: {'C': 0.9819722799632797, 'max_iter': 3746, 'k': 269}. Best is trial 7 with value: 0.2731404967843611.\n",
      "[I 2025-04-24 17:06:39,143] Trial 8 finished with value: 0.2700398190507444 and parameters: {'C': 3359.9229133716276, 'max_iter': 3366, 'k': 240}. Best is trial 7 with value: 0.2731404967843611.\n",
      "[I 2025-04-24 17:06:57,762] Trial 9 finished with value: 0.2728891247846697 and parameters: {'C': 0.004254520586899179, 'max_iter': 4829, 'k': 207}. Best is trial 7 with value: 0.2731404967843611.\n",
      "[I 2025-04-24 17:07:16,564] Trial 10 finished with value: 0.27106168786471885 and parameters: {'C': 0.02049892008327445, 'max_iter': 3795, 'k': 269}. Best is trial 7 with value: 0.2731404967843611.\n",
      "[I 2025-04-24 17:07:35,314] Trial 11 finished with value: 0.27699230698292526 and parameters: {'C': 0.0030891403989824926, 'max_iter': 4999, 'k': 295}. Best is trial 11 with value: 0.27699230698292526.\n",
      "[I 2025-04-24 17:07:54,181] Trial 12 finished with value: 0.27162249671998534 and parameters: {'C': 0.014446414839611142, 'max_iter': 3974, 'k': 299}. Best is trial 11 with value: 0.27699230698292526.\n",
      "[I 2025-04-24 17:08:13,072] Trial 13 finished with value: 0.28128407208104833 and parameters: {'C': 33.342160429620655, 'max_iter': 3688, 'k': 295}. Best is trial 13 with value: 0.28128407208104833.\n",
      "[I 2025-04-24 17:08:31,635] Trial 14 finished with value: 0.2324026800796362 and parameters: {'C': 1.3376103439409218e-05, 'max_iter': 4403, 'k': 296}. Best is trial 13 with value: 0.28128407208104833.\n",
      "[I 2025-04-24 17:08:49,624] Trial 15 finished with value: 0.26204315889756674 and parameters: {'C': 73.32162710951437, 'max_iter': 3601, 'k': 221}. Best is trial 13 with value: 0.28128407208104833.\n",
      "[I 2025-04-24 17:09:08,921] Trial 16 finished with value: 0.27514958257679806 and parameters: {'C': 140.84631921602212, 'max_iter': 4148, 'k': 286}. Best is trial 13 with value: 0.28128407208104833.\n",
      "[I 2025-04-24 17:09:28,406] Trial 17 finished with value: 0.2706258472594557 and parameters: {'C': 0.31667550194275573, 'max_iter': 4590, 'k': 239}. Best is trial 13 with value: 0.28128407208104833.\n",
      "[I 2025-04-24 17:09:47,518] Trial 18 finished with value: 0.24861793974564567 and parameters: {'C': 0.00043827547926673753, 'max_iter': 4966, 'k': 100}. Best is trial 13 with value: 0.28128407208104833.\n",
      "[I 2025-04-24 17:10:06,189] Trial 19 finished with value: 0.2772497134108777 and parameters: {'C': 0.16543840727153958, 'max_iter': 4037, 'k': 282}. Best is trial 13 with value: 0.28128407208104833.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc_pr</th>\n",
       "      <td>0.143026</td>\n",
       "      <td>0.279926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dummy  LogisticRegression RandomForest XGBoost CatBoost\n",
       "auc_pr  0.143026            0.279926          NaN     NaN      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    C = trial.suggest_float('C', 1e-5, 1e5, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 3000, 5000)\n",
    "    k = trial.suggest_int('k', 100, 300)\n",
    "\n",
    "    log_reg_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('standardize', StandardScaler()),\n",
    "        ('selector', SelectKBest(k=k)),\n",
    "        ('classifier', LogisticRegression(C=C, max_iter=max_iter, class_weight='balanced', n_jobs=-1)),\n",
    "    ])\n",
    "\n",
    "    log_reg_pipeline.fit(X_train_, y_train_)\n",
    "    trial.set_user_attr(\"model\", log_reg_pipeline)\n",
    "\n",
    "    y_pred = log_reg_pipeline.predict_proba(X_val)[:, 1]\n",
    "    return average_precision_score(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_log_reg = study.best_trial.user_attrs[\"model\"]\n",
    "\n",
    "y_pred = best_log_reg.predict_proba(X_val)[:, 1]\n",
    "metrics['LogisticRegression'] = average_precision_score(y_val, y_pred)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bc96c7b85602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 10:02:02,207] A new study created in memory with name: no-name-0d98c5ae-3173-4b59-b51b-3bf2de01cdb5\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/trial/_trial.py:678: RuntimeWarning: Inconsistent parameter values for distribution with name \"max_iter\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 5, 'high': 50}\n",
      "  warnings.warn(\n",
      "[I 2025-04-24 10:02:20,502] Trial 0 finished with value: 0.25301297938030143 and parameters: {'max_iter': 25, 'k': 112, 'max_features': 0.3, 'min_samples_split': 7, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.25301297938030143.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/trial/_trial.py:678: RuntimeWarning: Inconsistent parameter values for distribution with name \"max_iter\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 5, 'high': 50}\n",
      "  warnings.warn(\n",
      "[I 2025-04-24 10:02:38,054] Trial 1 finished with value: 0.26596898482286163 and parameters: {'max_iter': 6, 'k': 161, 'max_features': 0.7, 'min_samples_split': 18, 'min_samples_leaf': 15}. Best is trial 1 with value: 0.26596898482286163.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/trial/_trial.py:678: RuntimeWarning: Inconsistent parameter values for distribution with name \"max_iter\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 5, 'high': 50}\n",
      "  warnings.warn(\n",
      "[I 2025-04-24 10:02:55,335] Trial 2 finished with value: 0.31126774246449385 and parameters: {'max_iter': 28, 'k': 259, 'max_features': 0.5, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 2 with value: 0.31126774246449385.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/trial/_trial.py:678: RuntimeWarning: Inconsistent parameter values for distribution with name \"max_iter\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 5, 'high': 50}\n",
      "  warnings.warn(\n",
      "[I 2025-04-24 10:03:12,337] Trial 3 finished with value: 0.26183123767654615 and parameters: {'max_iter': 23, 'k': 238, 'max_features': 'log2', 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.31126774246449385.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/trial/_trial.py:678: RuntimeWarning: Inconsistent parameter values for distribution with name \"max_iter\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 5, 'high': 50}\n",
      "  warnings.warn(\n",
      "[I 2025-04-24 10:03:30,430] Trial 4 finished with value: 0.28954283454001434 and parameters: {'max_iter': 22, 'k': 269, 'max_features': 0.7, 'min_samples_split': 8, 'min_samples_leaf': 12}. Best is trial 2 with value: 0.31126774246449385.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/trial/_trial.py:678: RuntimeWarning: Inconsistent parameter values for distribution with name \"max_iter\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 5, 'high': 50}\n",
      "  warnings.warn(\n",
      "[W 2025-04-24 10:03:31,626] Trial 5 failed with parameters: {'max_iter': 49, 'k': 142, 'max_features': 'log2', 'min_samples_split': 16, 'min_samples_leaf': 13} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/vv/hdp_tqr92vj227jyt1bp9v7c0000gn/T/ipykernel_2844/2100634174.py\", line 31, in objective\n",
      "    forest_pipeline.fit(X_train_, y_train_)\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 1001, in fit_transform\n",
      "    result = self._call_func_on_transformers(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 910, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/notebooks/baseline_transformer.py\", line 25, in transform\n",
      "    mfccs = Parallel(n_jobs=self.n_jobs, prefer=\"threads\")(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-24 10:03:31,633] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m average_precision_score(y_val, y_pred)\n\u001b[32m     37\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     12\u001b[39m preprocessor = ColumnTransformer(\n\u001b[32m     13\u001b[39m     transformers=[\n\u001b[32m     14\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mbtf\u001b[39m\u001b[33m'\u001b[39m, btf.BaselineTransformer(), numeric_features),\n\u001b[32m     15\u001b[39m     ]\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m forest_pipeline = Pipeline(steps=[\n\u001b[32m     19\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m     20\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mselector\u001b[39m\u001b[33m'\u001b[39m, SelectKBest(k=k)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m         min_samples_leaf=min_samples_leaf)),\n\u001b[32m     29\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mforest_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m trial.set_user_attr(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, forest_pipeline)\n\u001b[32m     34\u001b[39m y_pred = forest_pipeline.predict_proba(X_val)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:654\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m     )\n\u001b[32m    653\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:588\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    582\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    583\u001b[39m     step_idx=step_idx,\n\u001b[32m    584\u001b[39m     step_params=routed_params[name],\n\u001b[32m    585\u001b[39m     all_params=raw_params,\n\u001b[32m    586\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/memory.py:312\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1551\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1553\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1554\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1555\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1001\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    999\u001b[39m     routed_params = \u001b[38;5;28mself\u001b[39m._get_empty_routing()\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[32m   1010\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fitted_transformers([])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:910\u001b[39m, in \u001b[36mColumnTransformer._call_func_on_transformers\u001b[39m\u001b[34m(self, X, y, func, column_as_labels, routed_params)\u001b[39m\n\u001b[32m    898\u001b[39m             extra_args = {}\n\u001b[32m    899\u001b[39m         jobs.append(\n\u001b[32m    900\u001b[39m             delayed(func)(\n\u001b[32m    901\u001b[39m                 transformer=clone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[32m   (...)\u001b[39m\u001b[32m    907\u001b[39m             )\n\u001b[32m    908\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1551\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1553\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1554\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1555\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/base.py:921\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/notebooks/baseline_transformer.py:25\u001b[39m, in \u001b[36mBaselineTransformer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     23\u001b[39m X = X.copy()\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Параллельно MFCC\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m mfccs = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_mfcc_single\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSR\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m X[\u001b[33m\"\u001b[39m\u001b[33mMFCC\u001b[39m\u001b[33m\"\u001b[39m] = mfccs\n\u001b[32m     30\u001b[39m X = StatFeatTransformer([\u001b[33m\"\u001b[39m\u001b[33mMFCC\u001b[39m\u001b[33m\"\u001b[39m]).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    max_depth = trial.suggest_int('max_iter', 5, 50)\n",
    "    n_estimators = trial.suggest_int('max_iter', 20, 100)\n",
    "    k = trial.suggest_int('k', 100, 300)\n",
    "\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.3, 0.5, 0.7])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "\n",
    "    forest_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('standardize', StandardScaler()),\n",
    "        ('selector', SelectKBest(k=k)),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            max_depth=max_depth, \n",
    "            n_jobs=-1, \n",
    "            class_weight='balanced', \n",
    "            n_estimators=n_estimators,\n",
    "            max_features=max_features,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf)),\n",
    "    ])\n",
    "\n",
    "    forest_pipeline.fit(X_train_, y_train_)\n",
    "    trial.set_user_attr(\"model\", forest_pipeline)\n",
    "\n",
    "    y_pred = forest_pipeline.predict_proba(X_val)[:, 1]\n",
    "    return average_precision_score(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b02d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc_pr</th>\n",
       "      <td>0.143026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dummy LogisticRegression  RandomForest XGBoost CatBoost\n",
       "auc_pr  0.143026                NaN      0.306642     NaN      NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = study.best_trial.user_attrs[\"model\"]\n",
    "\n",
    "y_pred = best_forest.predict_proba(X_val)[:, 1]\n",
    "metrics['RandomForest'] = average_precision_score(y_val, y_pred)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254fe1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 01:59:01,637] A new study created in memory with name: no-name-de8d8b91-bdb9-4baa-a114-ad8fce0abe00\n",
      "[I 2025-04-24 01:59:20,301] Trial 0 finished with value: 0.2510038780259412 and parameters: {'max_iter': 29, 'n_estimators': 201, 'learning_rate': 0.013896389498100903, 'k': 188, 'subsample': 0.5213797120458701, 'colsample_bytree': 0.9179400026754023, 'min_child_weight': 6, 'gamma': 0.5097243069986784}. Best is trial 0 with value: 0.2510038780259412.\n",
      "[I 2025-04-24 01:59:38,544] Trial 1 finished with value: 0.2572292831401991 and parameters: {'max_iter': 15, 'n_estimators': 133, 'learning_rate': 0.01761037553053986, 'k': 169, 'subsample': 0.79525016450707, 'colsample_bytree': 0.5041528089576843, 'min_child_weight': 8, 'gamma': 3.761582527341921}. Best is trial 1 with value: 0.2572292831401991.\n",
      "[I 2025-04-24 01:59:57,261] Trial 2 finished with value: 0.2658321042980574 and parameters: {'max_iter': 24, 'n_estimators': 293, 'learning_rate': 0.06691429009454082, 'k': 132, 'subsample': 0.5393007591620341, 'colsample_bytree': 0.7154617065181132, 'min_child_weight': 5, 'gamma': 1.6989054760972533}. Best is trial 2 with value: 0.2658321042980574.\n",
      "[I 2025-04-24 02:00:15,718] Trial 3 finished with value: 0.288060057638161 and parameters: {'max_iter': 33, 'n_estimators': 119, 'learning_rate': 0.014547039491772829, 'k': 125, 'subsample': 0.8074635210152141, 'colsample_bytree': 0.8023120446897373, 'min_child_weight': 9, 'gamma': 3.2196161718776994}. Best is trial 3 with value: 0.288060057638161.\n",
      "[I 2025-04-24 02:00:35,177] Trial 4 finished with value: 0.25174088998319566 and parameters: {'max_iter': 19, 'n_estimators': 127, 'learning_rate': 0.05023228781637031, 'k': 239, 'subsample': 0.7521564889116606, 'colsample_bytree': 0.8895587005189265, 'min_child_weight': 4, 'gamma': 0.49140605094494916}. Best is trial 3 with value: 0.288060057638161.\n",
      "[I 2025-04-24 02:00:53,765] Trial 5 finished with value: 0.2553024208974521 and parameters: {'max_iter': 13, 'n_estimators': 175, 'learning_rate': 0.11104968986812817, 'k': 152, 'subsample': 0.9655412766911393, 'colsample_bytree': 0.9425373196004354, 'min_child_weight': 7, 'gamma': 0.14807548670530968}. Best is trial 3 with value: 0.288060057638161.\n",
      "[I 2025-04-24 02:01:11,449] Trial 6 finished with value: 0.29469749992503746 and parameters: {'max_iter': 34, 'n_estimators': 80, 'learning_rate': 0.020432120246915746, 'k': 136, 'subsample': 0.9405647133212776, 'colsample_bytree': 0.6499624564028743, 'min_child_weight': 8, 'gamma': 3.057278841103375}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:01:29,581] Trial 7 finished with value: 0.26554063302448117 and parameters: {'max_iter': 14, 'n_estimators': 127, 'learning_rate': 0.07922713926539295, 'k': 149, 'subsample': 0.7418316725923426, 'colsample_bytree': 0.8455232837018727, 'min_child_weight': 7, 'gamma': 1.4463828216269143}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:01:47,339] Trial 8 finished with value: 0.2771688318764923 and parameters: {'max_iter': 44, 'n_estimators': 82, 'learning_rate': 0.018138283398440643, 'k': 153, 'subsample': 0.7176129826540489, 'colsample_bytree': 0.5177830385323441, 'min_child_weight': 6, 'gamma': 2.591395450365412}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:02:05,352] Trial 9 finished with value: 0.23485276747636952 and parameters: {'max_iter': 19, 'n_estimators': 212, 'learning_rate': 0.12640743679143712, 'k': 104, 'subsample': 0.5313374504702782, 'colsample_bytree': 0.7635783893428175, 'min_child_weight': 4, 'gamma': 4.567103004319152}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:02:24,727] Trial 10 finished with value: 0.2930554804495166 and parameters: {'max_iter': 42, 'n_estimators': 56, 'learning_rate': 0.03344791744397264, 'k': 299, 'subsample': 0.9864760503486053, 'colsample_bytree': 0.6491057666994446, 'min_child_weight': 1, 'gamma': 4.723668509970553}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:02:43,460] Trial 11 finished with value: 0.29104716764527266 and parameters: {'max_iter': 41, 'n_estimators': 56, 'learning_rate': 0.0351301308998645, 'k': 296, 'subsample': 0.9706282081647745, 'colsample_bytree': 0.6484538632901123, 'min_child_weight': 1, 'gamma': 4.9942897791413134}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:03:02,137] Trial 12 finished with value: 0.23778453030317404 and parameters: {'max_iter': 38, 'n_estimators': 50, 'learning_rate': 0.2970449430610099, 'k': 228, 'subsample': 0.884939732600613, 'colsample_bytree': 0.6285109085446074, 'min_child_weight': 1, 'gamma': 3.9232741632751953}. Best is trial 6 with value: 0.29469749992503746.\n",
      "[I 2025-04-24 02:03:21,670] Trial 13 finished with value: 0.2948636196550134 and parameters: {'max_iter': 50, 'n_estimators': 90, 'learning_rate': 0.028623681160852732, 'k': 291, 'subsample': 0.8931811272697645, 'colsample_bytree': 0.6122167193476191, 'min_child_weight': 10, 'gamma': 2.5982795736267454}. Best is trial 13 with value: 0.2948636196550134.\n",
      "[I 2025-04-24 02:03:39,455] Trial 14 finished with value: 0.2683451946990515 and parameters: {'max_iter': 50, 'n_estimators': 96, 'learning_rate': 0.028078926327525757, 'k': 259, 'subsample': 0.8796251594022311, 'colsample_bytree': 0.5840940623540243, 'min_child_weight': 10, 'gamma': 2.2979413010145135}. Best is trial 13 with value: 0.2948636196550134.\n",
      "[I 2025-04-24 02:03:56,954] Trial 15 finished with value: 0.2852703013897033 and parameters: {'max_iter': 5, 'n_estimators': 175, 'learning_rate': 0.01038970277719731, 'k': 209, 'subsample': 0.8963220929976359, 'colsample_bytree': 0.7061602373341611, 'min_child_weight': 10, 'gamma': 2.792692448153548}. Best is trial 13 with value: 0.2948636196550134.\n",
      "[I 2025-04-24 02:04:14,820] Trial 16 finished with value: 0.2832825160083262 and parameters: {'max_iter': 50, 'n_estimators': 95, 'learning_rate': 0.024650047711781146, 'k': 271, 'subsample': 0.6543361178403028, 'colsample_bytree': 0.5761586527987188, 'min_child_weight': 9, 'gamma': 1.768286942463732}. Best is trial 13 with value: 0.2948636196550134.\n",
      "[I 2025-04-24 02:04:33,198] Trial 17 finished with value: 0.2573070216807352 and parameters: {'max_iter': 34, 'n_estimators': 279, 'learning_rate': 0.04182112448745495, 'k': 178, 'subsample': 0.9134456094725952, 'colsample_bytree': 0.5714635076888499, 'min_child_weight': 8, 'gamma': 3.2831089976596415}. Best is trial 13 with value: 0.2948636196550134.\n",
      "[I 2025-04-24 02:04:52,111] Trial 18 finished with value: 0.2709336744391068 and parameters: {'max_iter': 45, 'n_estimators': 252, 'learning_rate': 0.02349242794268863, 'k': 214, 'subsample': 0.8229444491672119, 'colsample_bytree': 0.6970217001837439, 'min_child_weight': 9, 'gamma': 2.0822300173299926}. Best is trial 13 with value: 0.2948636196550134.\n",
      "[I 2025-04-24 02:05:09,455] Trial 19 finished with value: 0.281569391967252 and parameters: {'max_iter': 28, 'n_estimators': 150, 'learning_rate': 0.01176491646426868, 'k': 262, 'subsample': 0.9420157905178077, 'colsample_bytree': 0.6176113126809568, 'min_child_weight': 10, 'gamma': 1.1428169677388782}. Best is trial 13 with value: 0.2948636196550134.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc_pr</th>\n",
       "      <td>0.143026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306642</td>\n",
       "      <td>0.279541</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dummy LogisticRegression  RandomForest   XGBoost CatBoost\n",
       "auc_pr  0.143026                NaN      0.306642  0.279541      NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    max_depth = trial.suggest_int('max_iter', 5, 50)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    k = trial.suggest_int('k', 100, 300)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "\n",
    "    xgb_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('selector', SelectKBest(k=k)),\n",
    "        ('classifier', XGBClassifier(\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            min_child_weight=min_child_weight,\n",
    "            gamma=gamma,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    xgb_pipeline.fit(X_train_, y_train_)\n",
    "    trial.set_user_attr(\"model\", xgb_pipeline)\n",
    "\n",
    "    y_pred = xgb_pipeline.predict_proba(X_val)[:, 1]\n",
    "    return average_precision_score(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_xgb = study.best_trial.user_attrs[\"model\"]\n",
    "\n",
    "y_pred = best_xgb.predict_proba(X_val)[:, 1]\n",
    "metrics['XGBoost'] = average_precision_score(y_val, y_pred)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ed6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 10:05:06,331] A new study created in memory with name: no-name-5a56b8c9-0376-4dda-a7c9-8194cf6924e0\n",
      "[I 2025-04-24 10:05:27,171] Trial 0 finished with value: 0.25796128468608587 and parameters: {'depth': 8, 'iterations': 216, 'learning_rate': 0.11932286511631263, 'k': 158, 'l2_leaf_reg': 4.472944085952919, 'bagging_temperature': 0.888220556274977}. Best is trial 0 with value: 0.25796128468608587.\n",
      "[I 2025-04-24 10:05:46,083] Trial 1 finished with value: 0.252859450255697 and parameters: {'depth': 7, 'iterations': 89, 'learning_rate': 0.2710959753985784, 'k': 273, 'l2_leaf_reg': 0.5870308645113466, 'bagging_temperature': 0.528271354822106}. Best is trial 0 with value: 0.25796128468608587.\n",
      "[I 2025-04-24 10:06:08,026] Trial 2 finished with value: 0.27824276665562975 and parameters: {'depth': 9, 'iterations': 184, 'learning_rate': 0.14679752633464507, 'k': 128, 'l2_leaf_reg': 0.5638371181468764, 'bagging_temperature': 0.9234763385638954}. Best is trial 2 with value: 0.27824276665562975.\n",
      "[I 2025-04-24 10:06:26,727] Trial 3 finished with value: 0.24204599139325414 and parameters: {'depth': 6, 'iterations': 168, 'learning_rate': 0.22207261079971344, 'k': 205, 'l2_leaf_reg': 0.9763870148832167, 'bagging_temperature': 0.05809908822783405}. Best is trial 2 with value: 0.27824276665562975.\n",
      "[I 2025-04-24 10:06:45,144] Trial 4 finished with value: 0.27378806642622555 and parameters: {'depth': 6, 'iterations': 171, 'learning_rate': 0.23187159615976918, 'k': 284, 'l2_leaf_reg': 0.2774784302796635, 'bagging_temperature': 0.3741767825219702}. Best is trial 2 with value: 0.27824276665562975.\n",
      "[I 2025-04-24 10:07:10,010] Trial 5 finished with value: 0.2869792692131757 and parameters: {'depth': 10, 'iterations': 167, 'learning_rate': 0.013976476420083794, 'k': 173, 'l2_leaf_reg': 0.015777104686116112, 'bagging_temperature': 0.9279166819108258}. Best is trial 5 with value: 0.2869792692131757.\n",
      "[I 2025-04-24 10:07:28,484] Trial 6 finished with value: 0.2875614587327528 and parameters: {'depth': 5, 'iterations': 190, 'learning_rate': 0.15078478927483357, 'k': 206, 'l2_leaf_reg': 4.544064796766142, 'bagging_temperature': 0.45404135747422525}. Best is trial 6 with value: 0.2875614587327528.\n",
      "[I 2025-04-24 10:07:46,414] Trial 7 finished with value: 0.2724915291108136 and parameters: {'depth': 5, 'iterations': 86, 'learning_rate': 0.14934454412194825, 'k': 201, 'l2_leaf_reg': 3.7040666890849434, 'bagging_temperature': 0.9576203745648392}. Best is trial 6 with value: 0.2875614587327528.\n",
      "[I 2025-04-24 10:08:04,485] Trial 8 finished with value: 0.29914473742388153 and parameters: {'depth': 4, 'iterations': 113, 'learning_rate': 0.07249076332720637, 'k': 130, 'l2_leaf_reg': 8.708907912869515, 'bagging_temperature': 0.8176743633919199}. Best is trial 8 with value: 0.29914473742388153.\n",
      "[I 2025-04-24 10:08:23,808] Trial 9 finished with value: 0.2646935635761229 and parameters: {'depth': 6, 'iterations': 241, 'learning_rate': 0.21704779477647934, 'k': 215, 'l2_leaf_reg': 1.087954657587933, 'bagging_temperature': 0.673209175153634}. Best is trial 8 with value: 0.29914473742388153.\n",
      "[I 2025-04-24 10:08:41,615] Trial 10 finished with value: 0.3066025368242702 and parameters: {'depth': 4, 'iterations': 297, 'learning_rate': 0.04161229366809718, 'k': 105, 'l2_leaf_reg': 0.08336844829219121, 'bagging_temperature': 0.7449704424793729}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:08:59,196] Trial 11 finished with value: 0.27390289846332816 and parameters: {'depth': 4, 'iterations': 300, 'learning_rate': 0.04214411665843744, 'k': 100, 'l2_leaf_reg': 0.06965884347635323, 'bagging_temperature': 0.7200495860295614}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:09:16,507] Trial 12 finished with value: 0.2788676054327447 and parameters: {'depth': 4, 'iterations': 58, 'learning_rate': 0.049215152795111156, 'k': 103, 'l2_leaf_reg': 0.09583525038745513, 'bagging_temperature': 0.7155635125307115}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:09:34,143] Trial 13 finished with value: 0.2791403151591219 and parameters: {'depth': 4, 'iterations': 121, 'learning_rate': 0.026070423562411304, 'k': 140, 'l2_leaf_reg': 0.015476213486788211, 'bagging_temperature': 0.611322653180483}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:09:52,457] Trial 14 finished with value: 0.2952666006255727 and parameters: {'depth': 5, 'iterations': 296, 'learning_rate': 0.08770720110069566, 'k': 133, 'l2_leaf_reg': 0.06945836019256062, 'bagging_temperature': 0.8006637393447098}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:10:11,341] Trial 15 finished with value: 0.30245866519852793 and parameters: {'depth': 7, 'iterations': 126, 'learning_rate': 0.0277578006770302, 'k': 245, 'l2_leaf_reg': 9.059467269541006, 'bagging_temperature': 0.26452634969548866}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:10:34,298] Trial 16 finished with value: 0.262910773250223 and parameters: {'depth': 8, 'iterations': 263, 'learning_rate': 0.026131474773291148, 'k': 245, 'l2_leaf_reg': 0.18092276312396557, 'bagging_temperature': 0.21573377247211473}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:10:52,676] Trial 17 finished with value: 0.28389904143968564 and parameters: {'depth': 7, 'iterations': 117, 'learning_rate': 0.011146655122527074, 'k': 246, 'l2_leaf_reg': 0.025455351142197838, 'bagging_temperature': 0.27366485380532884}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:11:19,021] Trial 18 finished with value: 0.25693115559836843 and parameters: {'depth': 10, 'iterations': 136, 'learning_rate': 0.030774907690629186, 'k': 242, 'l2_leaf_reg': 0.15471259629487688, 'bagging_temperature': 0.06783443605242878}. Best is trial 10 with value: 0.3066025368242702.\n",
      "[I 2025-04-24 10:11:39,826] Trial 19 finished with value: 0.31359429667253236 and parameters: {'depth': 8, 'iterations': 217, 'learning_rate': 0.01865355118757212, 'k': 174, 'l2_leaf_reg': 1.7508720041596868, 'bagging_temperature': 0.22288518732452178}. Best is trial 19 with value: 0.31359429667253236.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc_pr</th>\n",
       "      <td>0.143026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306642</td>\n",
       "      <td>0.279541</td>\n",
       "      <td>0.285581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dummy LogisticRegression  RandomForest   XGBoost  CatBoost\n",
       "auc_pr  0.143026                NaN      0.306642  0.279541  0.285581"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    depth = trial.suggest_int('depth', 4, 10)\n",
    "    iterations = trial.suggest_int('iterations', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    k = trial.suggest_int('k', 100, 300)\n",
    "    l2_leaf_reg = trial.suggest_float('l2_leaf_reg', 1e-2, 10.0, log=True)\n",
    "    bagging_temperature = trial.suggest_float('bagging_temperature', 0.0, 1.0)\n",
    "\n",
    "    catboost_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('selector', SelectKBest(k=k)),\n",
    "        ('classifier', CatBoostClassifier(\n",
    "            depth=depth,\n",
    "            iterations=iterations,\n",
    "            learning_rate=learning_rate,\n",
    "            l2_leaf_reg=l2_leaf_reg,\n",
    "            bagging_temperature=bagging_temperature,\n",
    "            verbose=0,\n",
    "            eval_metric='Logloss',\n",
    "            thread_count=-1\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    catboost_pipeline.fit(X_train_, y_train_)\n",
    "    trial.set_user_attr(\"model\", catboost_pipeline)\n",
    "\n",
    "    y_pred = catboost_pipeline.predict_proba(X_val)[:, 1]\n",
    "    return average_precision_score(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_catboost = study.best_trial.user_attrs[\"model\"]\n",
    "\n",
    "y_pred = best_catboost.predict_proba(X_val)[:, 1]\n",
    "metrics['CatBoost'] = average_precision_score(y_val, y_pred)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fe0e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.143026</td>\n",
       "      <td>0.235981</td>\n",
       "      <td>0.306642</td>\n",
       "      <td>0.279541</td>\n",
       "      <td>0.285581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dummy  LogisticRegression  RandomForest   XGBoost  CatBoost\n",
       "baseline  0.143026            0.235981      0.306642  0.279541  0.285581"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c957fd8",
   "metadata": {},
   "source": [
    "## Улучшение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1c938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 20:12:04,190] A new study created in memory with name: no-name-9fb75d10-6fef-4d91-a837-4dffed02480f\n",
      "[I 2025-04-24 20:13:40,818] Trial 0 finished with value: 0.2567013207877382 and parameters: {'max_depth': 31, 'n_estimators': 86, 'k': 222, 'max_features': 'sqrt', 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.2567013207877382.\n",
      "[I 2025-04-24 20:15:16,444] Trial 1 finished with value: 0.29561026142147373 and parameters: {'max_depth': 41, 'n_estimators': 51, 'k': 282, 'max_features': 0.5, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:16:50,730] Trial 2 finished with value: 0.255652631911168 and parameters: {'max_depth': 17, 'n_estimators': 24, 'k': 174, 'max_features': 0.5, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:18:25,598] Trial 3 finished with value: 0.28567049069786465 and parameters: {'max_depth': 10, 'n_estimators': 22, 'k': 374, 'max_features': 'log2', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:20:00,036] Trial 4 finished with value: 0.25355801850534354 and parameters: {'max_depth': 20, 'n_estimators': 27, 'k': 190, 'max_features': 0.5, 'min_samples_split': 20, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:21:34,917] Trial 5 finished with value: 0.2891711908908008 and parameters: {'max_depth': 10, 'n_estimators': 74, 'k': 321, 'max_features': 0.3, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:23:09,015] Trial 6 finished with value: 0.2629296282365091 and parameters: {'max_depth': 46, 'n_estimators': 59, 'k': 373, 'max_features': 0.3, 'min_samples_split': 11, 'min_samples_leaf': 18}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:24:47,933] Trial 7 finished with value: 0.27917730494461623 and parameters: {'max_depth': 29, 'n_estimators': 49, 'k': 370, 'max_features': 'log2', 'min_samples_split': 5, 'min_samples_leaf': 17}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:26:22,225] Trial 8 finished with value: 0.2703374567324816 and parameters: {'max_depth': 48, 'n_estimators': 41, 'k': 181, 'max_features': 'log2', 'min_samples_split': 14, 'min_samples_leaf': 20}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:27:57,361] Trial 9 finished with value: 0.26951325946807575 and parameters: {'max_depth': 15, 'n_estimators': 82, 'k': 235, 'max_features': 0.3, 'min_samples_split': 7, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:29:32,421] Trial 10 finished with value: 0.2617960146820173 and parameters: {'max_depth': 38, 'n_estimators': 66, 'k': 112, 'max_features': 0.7, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.29561026142147373.\n",
      "[I 2025-04-24 20:31:06,971] Trial 11 finished with value: 0.3188345601535713 and parameters: {'max_depth': 7, 'n_estimators': 100, 'k': 300, 'max_features': 0.3, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:32:41,877] Trial 12 finished with value: 0.28551113355434754 and parameters: {'max_depth': 39, 'n_estimators': 45, 'k': 303, 'max_features': 0.5, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:34:19,441] Trial 13 finished with value: 0.2895219431201468 and parameters: {'max_depth': 36, 'n_estimators': 99, 'k': 285, 'max_features': 0.7, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:36:17,076] Trial 14 finished with value: 0.26024658203279655 and parameters: {'max_depth': 22, 'n_estimators': 99, 'k': 268, 'max_features': 'sqrt', 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:37:52,892] Trial 15 finished with value: 0.27048024398392895 and parameters: {'max_depth': 6, 'n_estimators': 56, 'k': 335, 'max_features': 0.3, 'min_samples_split': 15, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:39:28,680] Trial 16 finished with value: 0.2350090509818797 and parameters: {'max_depth': 25, 'n_estimators': 36, 'k': 257, 'max_features': 0.5, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:41:05,018] Trial 17 finished with value: 0.2426950920548835 and parameters: {'max_depth': 43, 'n_estimators': 67, 'k': 343, 'max_features': 0.3, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:42:42,033] Trial 18 finished with value: 0.28946753289217875 and parameters: {'max_depth': 34, 'n_estimators': 83, 'k': 294, 'max_features': 0.5, 'min_samples_split': 19, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.3188345601535713.\n",
      "[I 2025-04-24 20:44:16,141] Trial 19 finished with value: 0.24436691180911996 and parameters: {'max_depth': 42, 'n_estimators': 52, 'k': 395, 'max_features': 'sqrt', 'min_samples_split': 9, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.3188345601535713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее PR-AUC: 0.3188345601535713\n",
      "Гиперпараметры: {'max_depth': 7, 'n_estimators': 100, 'k': 300, 'max_features': 0.3, 'min_samples_split': 2, 'min_samples_leaf': 6}\n"
     ]
    }
   ],
   "source": [
    "# --- 0. зависимости ---\n",
    "# !pip install opensmile==2.5.0 optuna catboost\n",
    "\n",
    "import importlib, optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import baseline_transformer as btf\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# --- 1. OpenSMILE-трансформер ---\n",
    "import opensmile as sm\n",
    "_smile = sm.Smile(\n",
    "    feature_set=sm.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=sm.FeatureLevel.Functionals        # → 88 признаков\n",
    ")\n",
    "\n",
    "class OpenSmileTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" (Audio, SR)  →  матрица (n_samples, 88) \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        feats = []\n",
    "        for audio, sr in zip(X[\"Audio\"], X[\"SR\"]):\n",
    "            df = _smile.process_signal(audio, sr)\n",
    "            feats.append(df.values.squeeze())\n",
    "        return np.vstack(feats).astype(np.float32)\n",
    "\n",
    "# --- 2. разбор колонок ---\n",
    "categorical_features = ['Word ID']          # как и было\n",
    "audio_cols           = ['Audio', 'SR']      # нужны обоим аудио-блокам\n",
    "numeric_other        = (\n",
    "    X_train\n",
    "    .drop(columns=categorical_features + audio_cols)\n",
    "    .columns\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# --- 3. общий препроцессор ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat',   OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num',   'passthrough',                           numeric_other),\n",
    "        ('btf',   btf.BaselineTransformer(),              audio_cols),\n",
    "        ('smile', OpenSmileTransformer(),                 audio_cols),\n",
    "    ],\n",
    "    remainder='drop'      # всё нужное и так перечислили\n",
    ")\n",
    "\n",
    "# --- 4. Optuna-цель (+ мелкий фикс названий гиперпараметров) ---\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    max_depth          = trial.suggest_int('max_depth', 5, 50)\n",
    "    n_estimators       = trial.suggest_int('n_estimators', 20, 100)\n",
    "    k                  = trial.suggest_int('k', 100, 400)\n",
    "    max_features       = trial.suggest_categorical(\n",
    "                            'max_features', ['sqrt', 'log2', 0.3, 0.5, 0.7])\n",
    "    min_samples_split  = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf   = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "\n",
    "    forest_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        # масштабирем только непризнаковые столбцы\n",
    "        ('selector',     SelectKBest(score_func=f_classif, k=k)),\n",
    "        ('classifier',   RandomForestClassifier(\n",
    "                            max_depth=max_depth,\n",
    "                            n_estimators=n_estimators,\n",
    "                            max_features=max_features,\n",
    "                            min_samples_split=min_samples_split,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            n_jobs=-1,\n",
    "                            class_weight='balanced',\n",
    "                            random_state=42\n",
    "                        )),\n",
    "    ])\n",
    "\n",
    "    forest_pipeline.fit(X_train_, y_train_)\n",
    "    y_pred = forest_pipeline.predict_proba(X_val)[:, 1]\n",
    "    score  = average_precision_score(y_val, y_pred)\n",
    "    trial.set_user_attr(\"model\", forest_pipeline)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(storage=\"sqlite:///optuna_study.db\", direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print('Лучшее PR-AUC:', study.best_value)\n",
    "print('Гиперпараметры:', study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99773e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 11:39:43,379] A new study created in memory with name: no-name-00fc4a59-4197-41a0-8473-46599f59de65\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:40:13,623] Trial 0 finished with value: 0.20373352704671743 and parameters: {'max_depth': 39, 'n_estimators': 77, 'k': 1849, 'max_features': 'sqrt', 'min_samples_split': 19, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.20373352704671743.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:40:42,858] Trial 1 finished with value: 0.23144022661095204 and parameters: {'max_depth': 9, 'n_estimators': 21, 'k': 1273, 'max_features': 0.5, 'min_samples_split': 14, 'min_samples_leaf': 19}. Best is trial 1 with value: 0.23144022661095204.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:41:12,920] Trial 2 finished with value: 0.19625040803867505 and parameters: {'max_depth': 8, 'n_estimators': 41, 'k': 1053, 'max_features': 'log2', 'min_samples_split': 3, 'min_samples_leaf': 19}. Best is trial 1 with value: 0.23144022661095204.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:41:42,154] Trial 3 finished with value: 0.23622849384128997 and parameters: {'max_depth': 19, 'n_estimators': 48, 'k': 824, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 20}. Best is trial 3 with value: 0.23622849384128997.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:42:12,920] Trial 4 finished with value: 0.24634846224127654 and parameters: {'max_depth': 36, 'n_estimators': 40, 'k': 661, 'max_features': 0.5, 'min_samples_split': 9, 'min_samples_leaf': 19}. Best is trial 4 with value: 0.24634846224127654.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:42:44,154] Trial 5 finished with value: 0.24112302252430598 and parameters: {'max_depth': 37, 'n_estimators': 39, 'k': 920, 'max_features': 0.5, 'min_samples_split': 19, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.24634846224127654.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:43:15,086] Trial 6 finished with value: 0.19418091438577695 and parameters: {'max_depth': 5, 'n_estimators': 88, 'k': 354, 'max_features': 'log2', 'min_samples_split': 8, 'min_samples_leaf': 11}. Best is trial 4 with value: 0.24634846224127654.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:43:43,665] Trial 7 finished with value: 0.17194723677390128 and parameters: {'max_depth': 17, 'n_estimators': 54, 'k': 541, 'max_features': 'log2', 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.24634846224127654.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:44:16,580] Trial 8 finished with value: 0.20883997423534179 and parameters: {'max_depth': 49, 'n_estimators': 30, 'k': 1128, 'max_features': 0.5, 'min_samples_split': 4, 'min_samples_leaf': 17}. Best is trial 4 with value: 0.24634846224127654.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:45:01,727] Trial 9 finished with value: 0.21930068043801487 and parameters: {'max_depth': 44, 'n_estimators': 100, 'k': 607, 'max_features': 0.5, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.24634846224127654.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:45:38,193] Trial 10 finished with value: 0.2609897596823534 and parameters: {'max_depth': 31, 'n_estimators': 68, 'k': 1497, 'max_features': 0.3, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:46:14,261] Trial 11 finished with value: 0.21716570570333954 and parameters: {'max_depth': 30, 'n_estimators': 67, 'k': 1506, 'max_features': 0.3, 'min_samples_split': 15, 'min_samples_leaf': 14}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:46:49,627] Trial 12 finished with value: 0.2552158143330742 and parameters: {'max_depth': 29, 'n_estimators': 65, 'k': 1584, 'max_features': 0.3, 'min_samples_split': 7, 'min_samples_leaf': 15}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:47:22,918] Trial 13 finished with value: 0.2546797808406073 and parameters: {'max_depth': 26, 'n_estimators': 67, 'k': 1691, 'max_features': 0.3, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:47:55,314] Trial 14 finished with value: 0.23131434551519264 and parameters: {'max_depth': 27, 'n_estimators': 77, 'k': 1396, 'max_features': 0.3, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 11:54:31,530] Trial 15 finished with value: 0.20855220876683955 and parameters: {'max_depth': 19, 'n_estimators': 62, 'k': 1996, 'max_features': 0.7, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 12:24:26,197] Trial 16 finished with value: 0.23653115994765167 and parameters: {'max_depth': 31, 'n_estimators': 80, 'k': 1590, 'max_features': 0.3, 'min_samples_split': 6, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 12:55:55,311] Trial 17 finished with value: 0.24534134384042866 and parameters: {'max_depth': 23, 'n_estimators': 57, 'k': 1731, 'max_features': 0.3, 'min_samples_split': 12, 'min_samples_leaf': 11}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 13:11:25,760] Trial 18 finished with value: 0.22426513981088567 and parameters: {'max_depth': 33, 'n_estimators': 88, 'k': 1356, 'max_features': 0.7, 'min_samples_split': 16, 'min_samples_leaf': 16}. Best is trial 10 with value: 0.2609897596823534.\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [54] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/blnkoff/PycharmProjects/vocotrack/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2025-04-25 13:11:56,668] Trial 19 finished with value: 0.23469424023475863 and parameters: {'max_depth': 14, 'n_estimators': 71, 'k': 1513, 'max_features': 0.3, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.2609897596823534.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее PR-AUC: 0.2609897596823534\n",
      "Гиперпараметры: {'max_depth': 31, 'n_estimators': 68, 'k': 1497, 'max_features': 0.3, 'min_samples_split': 14, 'min_samples_leaf': 14}\n"
     ]
    }
   ],
   "source": [
    "from all_stats_transformer import AllStatsTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('btf', AllStatsTransformer(n_mfcc=50), numeric_features),\n",
    "    ])\n",
    "\n",
    "    max_depth          = trial.suggest_int('max_depth', 5, 50)\n",
    "    n_estimators       = trial.suggest_int('n_estimators', 20, 100)\n",
    "    k                  = trial.suggest_int('k', 300, 2000)\n",
    "    max_features       = trial.suggest_categorical(\n",
    "                            'max_features', ['sqrt', 'log2', 0.3, 0.5, 0.7])\n",
    "    min_samples_split  = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf   = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "\n",
    "    forest_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        # масштабирем только непризнаковые столбцы\n",
    "        ('selector',     SelectKBest(k=k)),\n",
    "        ('classifier',   RandomForestClassifier(\n",
    "                            max_depth=max_depth,\n",
    "                            n_estimators=n_estimators,\n",
    "                            max_features=max_features,\n",
    "                            min_samples_split=min_samples_split,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            n_jobs=-1,\n",
    "                            class_weight='balanced',\n",
    "                            random_state=42\n",
    "                        )),\n",
    "    ])\n",
    "\n",
    "    forest_pipeline.fit(X_train_, y_train_)\n",
    "    y_pred = forest_pipeline.predict_proba(X_val)[:, 1]\n",
    "    score  = average_precision_score(y_val, y_pred)\n",
    "    trial.set_user_attr(\"model\", forest_pipeline)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "print('Лучшее PR-AUC:', study.best_value)\n",
    "print('Гиперпараметры:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225caf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
